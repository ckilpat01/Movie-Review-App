# -*- coding: utf-8 -*-
"""Movie-Review-App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JE8vhAl1u_fQHbCIWKys1Im_MnXlfi0f

**RAQA LangChain Application Querying IMDB Reviews For The Napoleon Movie

***Scope***
* This notebook demonstrates a Retrieval And Question Answering (RAQA) application for the movie "Napoleon".
* Movie reviews scraped from the IMDB movie review website are the document source.
"""

# Commented out IPython magic to ensure Python compatibility.
# Install libraries
# %pip install --upgrade --quiet  langchain==0.2.0
!pip install -q -U faiss-cpu==1.7.2
!pip install -q -U requests==2.31.0
!pip install -q -U scrapy==2.11.2 selenium==4.21.0
!apt install chromium-chromedriver

# Obtain OpenAI key
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

# Import libraries
from langchain import hub
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.document_loaders.csv_loader import CSVLoader
from langchain.embeddings import CacheBackedEmbeddings
from langchain.vectorstores import FAISS
from langchain.storage import LocalFileStore
from langchain.chains import RetrievalQA
from langchain.callbacks import StdOutCallbackHandler
import pandas as pd
import tensorflow as tf
import numpy as np
from scrapy.selector import Selector
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# Remove limit on column display width
pd.options.display.max_colwidth = None

# Utilize GPU if available
# Get the list of available physical devices
physical_devices = tf.config.list_physical_devices('GPU')

if len(physical_devices) > 0:
    # If a GPU is available, use it
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
    device = "/GPU:0"
    print("Using GPU")
else:
    # If no GPU is available, use CPU
    device = "/CPU:0"
    print("Using CPU")

# Select LLM
llm = ChatOpenAI(model="gpt-3.5-turbo-0125")

"""**Scraping IMDB Reviews of Napoleon**"""

# Set chrome options for scraping
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome(options=chrome_options)

# Define Napoleon movie review URL
url = "https://www.imdb.com/title/tt13287846/reviews/?ref_=tt_ql_2"
driver.get(url)

# Define selector
sel = Selector(text = driver.page_source)
review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]
more_review_pages = int(int(review_counts)/25)

# Import data
for i in tqdm(range(more_review_pages)):
    try:
        css_selector = 'load-more-trigger'
        driver.find_element(By.ID, css_selector).click()
    except:
        pass

# Define DataFrame columns and append
rating_list = []
review_date_list = []
review_title_list = []
author_list = []
review_list = []
review_url_list = []
error_url_list = []
error_msg_list = []
reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')

for d in tqdm(reviews):
    try:
        sel2 = Selector(text = d.get_attribute('innerHTML'))
        try:
            rating = sel2.css('.rating-other-user-rating span::text').extract_first()
        except:
            rating = np.NaN
        try:
            review = sel2.css('.text.show-more__control::text').extract_first()
        except:
            review = np.NaN
        try:
            review_date = sel2.css('.review-date::text').extract_first()
        except:
            review_date = np.NaN
        try:
            author = sel2.css('.display-name-link a::text').extract_first()
        except:
            author = np.NaN
        try:
            review_title = sel2.css('a.title::text').extract_first()
        except:
            review_title = np.NaN
        try:
            review_url = sel2.css('a.title::attr(href)').extract_first()
        except:
            review_url = np.NaN
        rating_list.append(rating)
        review_date_list.append(review_date)
        review_title_list.append(review_title)
        author_list.append(author)
        review_list.append(review)
        review_url_list.append(review_url)
    except Exception as e:
        error_url_list.append(url)
        error_msg_list.append(e)
review_df = pd.DataFrame({
    'Review_Date':review_date_list,
    'Author':author_list,
    'Rating':rating_list,
    'Review_Title':review_title_list,
    'Review':review_list,
    'Review_Url':review_url
    })

# Print DataFrame
review_df

# Convert DataFrame to CSV
review_df.to_csv("./review.csv")

# Load data
loader = CSVLoader(
    file_path= './review.csv',
    source_column = 'Review_Url'
    )

data = loader.load()

# Print data and show length
print(data)
len(data)

# Define text splitter
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1000, # the character length of the chunk
    chunk_overlap = 100, # the character length of the overlap between chunks
    length_function = len # the length function
)

# Transform data
documents = text_splitter.transform_documents(data)

# Print documents
print(documents)

# Show documents length
len(documents)

# Define embedder and vector store
store = LocalFileStore('./cache/')

core_embeddings_model = OpenAIEmbeddings()

embedder = CacheBackedEmbeddings.from_bytes_store(
    core_embeddings_model, store, namespace = core_embeddings_model.model
)

vector_store = FAISS.from_documents(documents, embedder)

# Implement a query
query = "Which actor is the star of this movie?"
embedding_vector = core_embeddings_model.embed_query(query)
docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)

for page in docs:
  print(page.page_content)

# Commented out IPython magic to ensure Python compatibility.
# # Comparison for cached embedding
# %%timeit -n 1 -r 1
# query = "Which actor is the star of this movie?"
# embedding_vector = core_embeddings_model.embed_query(query)
# docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)

# Commented out IPython magic to ensure Python compatibility.
# Comparison for cached embedding
# %timeit
query = "Which actor is the star of this movie?"
embedding_vector = core_embeddings_model.embed_query(query)
docs = vector_store.similarity_search_by_vector(embedding_vector, k = 4)

# Define retriever
retriever = vector_store.as_retriever()

# Define retrieval chain
handler = StdOutCallbackHandler()

qa_with_sources_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    callbacks=[handler],
    return_source_documents=True
)

# Demonstrate question and answering
qa_with_sources_chain.invoke({"query" : "How was Joaquin Phoenix in this movie?"})

# Demonstrate question answering
qa_with_sources_chain.invoke({"query" : "Was it worthwhile to watch this movie?"})

"""**Conclusion
* The RAQA application has been completed and will be implemented as a HuggingFace space.
"""